{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tools\n",
    "\n",
    "import tools.baseline as bt\n",
    "import tools.data as data_tools\n",
    "import tools.baseline as baseline_tools\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input\n",
    "from collections import defaultdict\n",
    "\n",
    "from keras.layers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ASI', 'de', 'sencillas', '#laroca', '#diamantes', '#love', '#boda', '#tantan', 'üíçüíéüë∞üë∞', '#lasnovias', '#soon', '#pronto', '@chiquibabyla', '‚Ä¶', 'http://t.co/l7PmfXgLgG'], ['INFAMOUS', 'SECOND', 'SON', '|', 'KRONNO', 'ZOMBER', '|', '¬ø', 'HEROE', 'O', 'VILLANO', '?', '(', 'Prod', '.', 'por', 'Sa', '..', '.', 'https://t.co/3p0B0FdM5w', 'v√≠a', '@YouTube'], ['Apartamento', '317', '.', 'Shit', \"'s\", 'gonna', 'go', 'doooooown', '@lorraine_otero', '‚ú®‚ú®‚ú®'], ['Slippery', 'slope', ':', 'Algo', 'as√≠', 'como', 'bola', 'de', 'nieve', '(', 'que', 'lleva', 'a', 'algo', 'peor', ')', '.', 'Some', 'people', 'believe', 'that', 'euthanasia', 'is', 'the', 'slippery', 'slope', 'to', 'murder', '.'], ['La', 'kid', 'üë∂üèΩüë∂üèΩüë∂üèΩüë∂üèΩ', 'https://t.co/HbmdM3NOZw']]\n"
     ]
    }
   ],
   "source": [
    "dt_path = \"./data_files/train_conll_spanglish.txt\"\n",
    "embed_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "data = data_tools.Data(dt_path, shuffle=True, split=0.8)\n",
    "\n",
    "Xtrain, Ytrain, Xtest, Ytest = data.output_data()\n",
    "\n",
    "#print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)\n",
    "\n",
    "print(Xtrain[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "toki = Tokenizer(oov_token = 'UNK')\n",
    "toki.fit_on_texts(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_seq = toki.texts_to_sequences(Xtrain)\n",
    "Xtest_seq = toki.texts_to_sequences(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[311, 3, 6438, 6439, 9937, 1122, 2246, 9938, 9939, 9940, 4840, 9941, 1243, 28, 9942], [1801, 1171, 124, 49, 107, 125, 49, 127, 3317, 81, 3318, 24, 51, 1425, 2, 32, 6440, 18, 2, 6441, 151, 93], [6442, 6443, 2, 205, 90, 499, 162, 9943, 2247, 9944], [3911, 6444, 4, 117, 173, 45, 6445, 3, 4841, 51, 8, 1327, 6, 117, 854, 69, 2, 363, 628, 1538, 65, 9945, 53, 26, 3911, 6444, 31, 4842, 2], [13, 1996, 9946, 9947]]\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain_seq[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "word2index = toki.word_index\n",
    "word2index['PAD'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK\n"
     ]
    }
   ],
   "source": [
    "index2word = toki.index_word\n",
    "index2word[0] = 'PAD'\n",
    "print(index2word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "#get max length of words\n",
    "\n",
    "lens = [len(word) for word in word2index.keys()]\n",
    "max_len = max(lens)\n",
    "\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-pad the tweets with value 0\n",
    "Xtrain_pad = pad_sequences(Xtrain_seq, maxlen = max_len)\n",
    "Xtest_pad = pad_sequences(Xtest_seq, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'neutral', 'positive', 'negative', 'positive']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    'neutral':0,\n",
    "    'positive':1,\n",
    "    'negative':2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = [label_dict[label] for label in Ytrain]\n",
    "Ytest = [label_dict[label] for label in Ytest] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_cat = np.asarray([to_categorical(label, num_classes = 3) for label in Ytrain])\n",
    "Ytest_cat = np.asarray([to_categorical(label, num_classes = 3) for label in Ytest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_cat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (12000, 69)\n",
      "Shape of label tensor: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', Xtrain_pad.shape)\n",
    "print('Shape of label tensor:', Ytrain_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = KeyedVectors.load_word2vec_format(embed_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an index2embedding dict\n",
    "\n",
    "index2emb = dict()\n",
    "\n",
    "for i, w in index2word.items():\n",
    "    try:\n",
    "        embed = embeddings[w]\n",
    "    except KeyError:\n",
    "        embed = embeddings['UNK']\n",
    "    index2emb[i] = embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute embedding matrix\n",
    "\n",
    "embedding_matrix = np.zeros((len(word2index) + 1, 300))\n",
    "for word, i in word2index.items():\n",
    "    embedding_vector = index2emb[i]\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load embedding matrix into embedding layer\n",
    "\n",
    "\n",
    "embedding_layer = Embedding(len(word2index) + 1,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the classifier - FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.05\n",
    "batch = 512\n",
    "activation = 'softmax'\n",
    "loss_function = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 69)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 69, 300)           8363700   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 8,457,335\n",
      "Trainable params: 93,635\n",
      "Non-trainable params: 8,363,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "#flat = Flatten()(embedded_sequences)\n",
    "\n",
    "output_1 = LSTM(64, activation='relu')(embedded_sequences)\n",
    "#output_2 = Dense(64, activation='relu')(output_1)\n",
    "predictions = Dense(3, activation='softmax')(output_1)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=predictions)\n",
    "\n",
    "model.compile(loss=loss_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12000/12000 [==============================] - 4s 344us/step - loss: 0.7741 - accuracy: 0.6451\n",
      "Epoch 2/100\n",
      "12000/12000 [==============================] - 4s 341us/step - loss: 0.7653 - accuracy: 0.6485\n",
      "Epoch 3/100\n",
      "12000/12000 [==============================] - 4s 338us/step - loss: 0.7576 - accuracy: 0.6533\n",
      "Epoch 4/100\n",
      "12000/12000 [==============================] - 4s 345us/step - loss: 0.7489 - accuracy: 0.6600\n",
      "Epoch 5/100\n",
      "12000/12000 [==============================] - 4s 350us/step - loss: 0.7431 - accuracy: 0.6618\n",
      "Epoch 6/100\n",
      "12000/12000 [==============================] - 4s 344us/step - loss: 0.7347 - accuracy: 0.6668\n",
      "Epoch 7/100\n",
      "12000/12000 [==============================] - 4s 345us/step - loss: 0.7274 - accuracy: 0.6701\n",
      "Epoch 8/100\n",
      "12000/12000 [==============================] - 4s 342us/step - loss: 0.7204 - accuracy: 0.6747\n",
      "Epoch 9/100\n",
      "12000/12000 [==============================] - 4s 353us/step - loss: 0.7132 - accuracy: 0.6795\n",
      "Epoch 10/100\n",
      "12000/12000 [==============================] - 5s 377us/step - loss: 0.7052 - accuracy: 0.6826\n",
      "Epoch 11/100\n",
      "12000/12000 [==============================] - 5s 399us/step - loss: 0.6985 - accuracy: 0.6850\n",
      "Epoch 12/100\n",
      "12000/12000 [==============================] - 5s 442us/step - loss: 0.6919 - accuracy: 0.6896\n",
      "Epoch 13/100\n",
      "12000/12000 [==============================] - 5s 453us/step - loss: 0.6859 - accuracy: 0.6913\n",
      "Epoch 14/100\n",
      "12000/12000 [==============================] - 5s 423us/step - loss: 0.6777 - accuracy: 0.6963\n",
      "Epoch 15/100\n",
      "12000/12000 [==============================] - 5s 438us/step - loss: 0.6732 - accuracy: 0.6982\n",
      "Epoch 16/100\n",
      "12000/12000 [==============================] - 5s 433us/step - loss: 0.6646 - accuracy: 0.7019\n",
      "Epoch 17/100\n",
      "12000/12000 [==============================] - 5s 458us/step - loss: 0.6604 - accuracy: 0.7028\n",
      "Epoch 18/100\n",
      "12000/12000 [==============================] - 5s 429us/step - loss: 0.6540 - accuracy: 0.7090\n",
      "Epoch 19/100\n",
      "12000/12000 [==============================] - 5s 393us/step - loss: 0.6458 - accuracy: 0.7132\n",
      "Epoch 20/100\n",
      "12000/12000 [==============================] - 4s 363us/step - loss: 0.6384 - accuracy: 0.7127\n",
      "Epoch 21/100\n",
      "12000/12000 [==============================] - 4s 365us/step - loss: 0.6335 - accuracy: 0.7209\n",
      "Epoch 22/100\n",
      "12000/12000 [==============================] - 4s 363us/step - loss: 0.6329 - accuracy: 0.7151\n",
      "Epoch 23/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.6225 - accuracy: 0.7218\n",
      "Epoch 24/100\n",
      "12000/12000 [==============================] - 4s 364us/step - loss: 0.6204 - accuracy: 0.7236\n",
      "Epoch 25/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.6144 - accuracy: 0.7296\n",
      "Epoch 26/100\n",
      "12000/12000 [==============================] - 4s 363us/step - loss: 0.6071 - accuracy: 0.7310\n",
      "Epoch 27/100\n",
      "12000/12000 [==============================] - 4s 365us/step - loss: 0.5979 - accuracy: 0.7340\n",
      "Epoch 28/100\n",
      "12000/12000 [==============================] - 4s 365us/step - loss: 0.5942 - accuracy: 0.7368\n",
      "Epoch 29/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.5877 - accuracy: 0.7400\n",
      "Epoch 30/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.5813 - accuracy: 0.7433\n",
      "Epoch 31/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.5750 - accuracy: 0.7450\n",
      "Epoch 32/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.5693 - accuracy: 0.7472\n",
      "Epoch 33/100\n",
      "12000/12000 [==============================] - 4s 364us/step - loss: 0.5646 - accuracy: 0.7513\n",
      "Epoch 34/100\n",
      "12000/12000 [==============================] - 4s 365us/step - loss: 0.5558 - accuracy: 0.7563\n",
      "Epoch 35/100\n",
      "12000/12000 [==============================] - 4s 363us/step - loss: 0.5510 - accuracy: 0.7573\n",
      "Epoch 36/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.5501 - accuracy: 0.7606\n",
      "Epoch 37/100\n",
      "12000/12000 [==============================] - 4s 365us/step - loss: 0.5373 - accuracy: 0.7648\n",
      "Epoch 38/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.5308 - accuracy: 0.7685\n",
      "Epoch 39/100\n",
      "12000/12000 [==============================] - 4s 360us/step - loss: 0.5281 - accuracy: 0.7695\n",
      "Epoch 40/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.5191 - accuracy: 0.7747\n",
      "Epoch 41/100\n",
      "12000/12000 [==============================] - 4s 366us/step - loss: 0.5184 - accuracy: 0.7713\n",
      "Epoch 42/100\n",
      "12000/12000 [==============================] - 4s 365us/step - loss: 0.5150 - accuracy: 0.7756\n",
      "Epoch 43/100\n",
      "12000/12000 [==============================] - 4s 366us/step - loss: 0.5082 - accuracy: 0.7828\n",
      "Epoch 44/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.4932 - accuracy: 0.7876\n",
      "Epoch 45/100\n",
      "12000/12000 [==============================] - 4s 363us/step - loss: 0.4913 - accuracy: 0.7878\n",
      "Epoch 46/100\n",
      "12000/12000 [==============================] - 4s 360us/step - loss: 0.4844 - accuracy: 0.7944\n",
      "Epoch 47/100\n",
      "12000/12000 [==============================] - 4s 364us/step - loss: 0.5036 - accuracy: 0.7846\n",
      "Epoch 48/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.4901 - accuracy: 0.7925\n",
      "Epoch 49/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.4687 - accuracy: 0.8009\n",
      "Epoch 50/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.4658 - accuracy: 0.8008\n",
      "Epoch 51/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.4592 - accuracy: 0.8058\n",
      "Epoch 52/100\n",
      "12000/12000 [==============================] - 4s 360us/step - loss: 0.4499 - accuracy: 0.8090\n",
      "Epoch 53/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.4397 - accuracy: 0.8155\n",
      "Epoch 54/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.4345 - accuracy: 0.8158\n",
      "Epoch 55/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.4384 - accuracy: 0.8147\n",
      "Epoch 56/100\n",
      "12000/12000 [==============================] - 4s 360us/step - loss: 0.4321 - accuracy: 0.8212\n",
      "Epoch 57/100\n",
      "12000/12000 [==============================] - 4s 363us/step - loss: 0.7333 - accuracy: 0.6987\n",
      "Epoch 58/100\n",
      "12000/12000 [==============================] - 4s 358us/step - loss: 0.6533 - accuracy: 0.7125\n",
      "Epoch 59/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.5786 - accuracy: 0.7550\n",
      "Epoch 60/100\n",
      "12000/12000 [==============================] - 4s 360us/step - loss: 0.5198 - accuracy: 0.7839\n",
      "Epoch 61/100\n",
      "12000/12000 [==============================] - 4s 366us/step - loss: 0.4753 - accuracy: 0.8037\n",
      "Epoch 62/100\n",
      "12000/12000 [==============================] - 4s 360us/step - loss: 0.4513 - accuracy: 0.8119\n",
      "Epoch 63/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.4323 - accuracy: 0.8196\n",
      "Epoch 64/100\n",
      "12000/12000 [==============================] - 4s 359us/step - loss: 0.4184 - accuracy: 0.8282\n",
      "Epoch 65/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.4105 - accuracy: 0.8301\n",
      "Epoch 66/100\n",
      "12000/12000 [==============================] - 4s 358us/step - loss: 0.3994 - accuracy: 0.8377\n",
      "Epoch 67/100\n",
      "12000/12000 [==============================] - 4s 363us/step - loss: 0.3942 - accuracy: 0.8372\n",
      "Epoch 68/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.3886 - accuracy: 0.8416\n",
      "Epoch 69/100\n",
      "12000/12000 [==============================] - 4s 370us/step - loss: 0.4294 - accuracy: 0.8225\n",
      "Epoch 70/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.4006 - accuracy: 0.8374\n",
      "Epoch 71/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.3768 - accuracy: 0.8476\n",
      "Epoch 72/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.3646 - accuracy: 0.8496\n",
      "Epoch 73/100\n",
      "12000/12000 [==============================] - 4s 363us/step - loss: 0.3579 - accuracy: 0.8551\n",
      "Epoch 74/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.3502 - accuracy: 0.8589\n",
      "Epoch 75/100\n",
      "12000/12000 [==============================] - 4s 363us/step - loss: 0.3454 - accuracy: 0.8627\n",
      "Epoch 76/100\n",
      "12000/12000 [==============================] - 4s 360us/step - loss: 0.3389 - accuracy: 0.8654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.3329 - accuracy: 0.8669\n",
      "Epoch 78/100\n",
      "12000/12000 [==============================] - 4s 359us/step - loss: 0.3324 - accuracy: 0.8660\n",
      "Epoch 79/100\n",
      "12000/12000 [==============================] - 4s 363us/step - loss: 0.3312 - accuracy: 0.8672\n",
      "Epoch 80/100\n",
      "12000/12000 [==============================] - 4s 365us/step - loss: 0.3449 - accuracy: 0.8629\n",
      "Epoch 81/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.3235 - accuracy: 0.8761\n",
      "Epoch 82/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.3056 - accuracy: 0.8817\n",
      "Epoch 83/100\n",
      "12000/12000 [==============================] - 4s 359us/step - loss: 0.3000 - accuracy: 0.8810\n",
      "Epoch 84/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.2938 - accuracy: 0.8845\n",
      "Epoch 85/100\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.2880 - accuracy: 0.8904\n",
      "Epoch 86/100\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.2837 - accuracy: 0.8917\n",
      "Epoch 87/100\n",
      "12000/12000 [==============================] - 4s 364us/step - loss: 0.2756 - accuracy: 0.8962\n",
      "Epoch 88/100\n",
      "12000/12000 [==============================] - 4s 360us/step - loss: 0.2816 - accuracy: 0.8934\n",
      "Epoch 89/100\n",
      "12000/12000 [==============================] - 4s 364us/step - loss: 0.2700 - accuracy: 0.8972\n",
      "Epoch 90/100\n",
      "12000/12000 [==============================] - 5s 382us/step - loss: 0.2627 - accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "12000/12000 [==============================] - 5s 384us/step - loss: 0.2608 - accuracy: 0.9020\n",
      "Epoch 92/100\n",
      "12000/12000 [==============================] - 5s 388us/step - loss: 0.2523 - accuracy: 0.9032\n",
      "Epoch 93/100\n",
      "12000/12000 [==============================] - 5s 379us/step - loss: 0.2535 - accuracy: 0.9042\n",
      "Epoch 94/100\n",
      "12000/12000 [==============================] - 5s 380us/step - loss: 0.2529 - accuracy: 0.9043\n",
      "Epoch 95/100\n",
      "12000/12000 [==============================] - 4s 375us/step - loss: 0.2416 - accuracy: 0.9095\n",
      "Epoch 96/100\n",
      "12000/12000 [==============================] - 5s 382us/step - loss: 0.2451 - accuracy: 0.9077\n",
      "Epoch 97/100\n",
      "12000/12000 [==============================] - 4s 367us/step - loss: 0.2336 - accuracy: 0.9133\n",
      "Epoch 98/100\n",
      "12000/12000 [==============================] - 4s 373us/step - loss: 0.2244 - accuracy: 0.9176\n",
      "Epoch 99/100\n",
      "12000/12000 [==============================] - 4s 374us/step - loss: 0.2201 - accuracy: 0.9190\n",
      "Epoch 100/100\n",
      "12000/12000 [==============================] - 4s 369us/step - loss: 0.2176 - accuracy: 0.9196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fcc8c29e780>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain_pad, Ytrain_cat, batch_size = batch, epochs=epochs, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(Xtest_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.28      0.33      1009\n",
      "           1       0.55      0.74      0.63      1489\n",
      "           2       0.42      0.23      0.29       502\n",
      "\n",
      "    accuracy                           0.50      3000\n",
      "   macro avg       0.45      0.42      0.42      3000\n",
      "weighted avg       0.48      0.50      0.47      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(predictions, axis=1)\n",
    "Ytest_converted = np.argmax(Ytest_cat, axis=1)\n",
    "\n",
    "print(classification_report(Ytest_converted, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
